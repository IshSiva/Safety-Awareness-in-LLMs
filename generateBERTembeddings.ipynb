{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from config import *\n",
    "import pickle as pkl\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nethome/ss651/miniconda3/envs/sp/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "model = torch.nn.DataParallel(model)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-16 12:59:41.750001: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-16 12:59:52.388474: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "850\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "6980\n",
      "10000\n",
      "10000\n",
      "6420\n",
      "939\n"
     ]
    }
   ],
   "source": [
    "files = [file for file in os.listdir(\"./raw_data/\") if file.endswith(\".csv\")]\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for file in files:\n",
    "        data = pd.read_csv(\"./raw_data/\"+file)\n",
    "        data = data.dropna()\n",
    "        data = data.sample(min(10000, len(data)))\n",
    "        \n",
    "        file_name = file[:-4]\n",
    "        text_column = dataset_category_mapping[file_name][\"column_text\"]\n",
    "        data = data[data[text_column].apply(lambda x: isinstance(x, str))]\n",
    "        print(len(data))\n",
    "        \n",
    "        text = data[text_column].tolist()\n",
    "        labels = data[dataset_category_mapping[file_name][\"column_name\"]]\n",
    "        label2id = dataset_category_mapping[file_name][\"column_mapping\"]\n",
    "\n",
    "        data_loader = DataLoader(text, batch_size=512, shuffle=False)\n",
    "        activations = []\n",
    "        for batch in data_loader:\n",
    "            encoded_text = tokenizer(batch, return_tensors='pt', padding=True, truncation=True, max_length=512).to(device)\n",
    "            output = model(**encoded_text)\n",
    "            activations.extend(output.pooler_output.detach().cpu().numpy())\n",
    "        \n",
    "        results = {}\n",
    "        results['activations'] = activations\n",
    "        results['labels'] = [label2id[x] for x in labels.tolist()]\n",
    "        \n",
    "        pkl.dump(results, open(\"./BERTembeddings/\"+file_name+\".pkl\", \"wb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /nethome/ss651/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e1f6ba5c5fc463b8e19f695942d89ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "bullying.pkl:   0%|          | 0.00/31.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4e4e2dde7f04ce79e25d99a6589130d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "do_not_answer_en.pkl:   0%|          | 0.00/2.92M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "605827c94d814cd98589608ca44987ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "abuse.pkl:   0%|          | 0.00/9.32M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c22a5a918ef0439ca96a0d4a10c7eb36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 10 LFS files:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c113b8a42cb14c50a8f82e45134e9839",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adult_content.pkl:   0%|          | 0.00/2.64M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d435ac20c98043ffb17ed69924958270",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "covid_fake_news.pkl:   0%|          | 0.00/20.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56f0a3fe4cf74a01b349f001ebbe2b16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "hate_speech.pkl:   0%|          | 0.00/31.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ec80f8749df4f859b59a791c0f9604d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "mis_information.pkl:   0%|          | 0.00/31.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc861737e1924e01918237cc69ded32a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "student_anxiety.pkl:   0%|          | 0.00/21.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b7dafb6e2f24987afff4eb976e312a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "toxigen.pkl:   0%|          | 0.00/31.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "411a0c5919a54533bb07ea0a0ae8ca35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "true_false.pkl:   0%|          | 0.00/31.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'https://huggingface.co/datasets/saiprasath21/safety_awareness/tree/main/BERTembeddings/'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "login(token = \"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\")\n",
    "\n",
    "from huggingface_hub import HfApi\n",
    "api = HfApi()\n",
    "\n",
    "api.upload_folder(\n",
    "    folder_path=\"./BERTembeddings/\",\n",
    "    path_in_repo=\"BERTembeddings/\",\n",
    "    repo_id=\"saiprasath21/safety_awareness\",\n",
    "    repo_type=\"dataset\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
