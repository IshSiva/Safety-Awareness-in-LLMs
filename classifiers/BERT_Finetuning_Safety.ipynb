{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4OLtUm6TWePm"
      },
      "outputs": [],
      "source": [
        "\n",
        "import torch\n",
        "from torch.jit import script, trace\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import math\n",
        "import pickle\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import tqdm\n",
        "import nltk\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda\")\n",
        "else:\n",
        "  device = torch.device(\"cpu\")\n",
        "print(\"Using device:\", device)\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_UlxozKJhcw6",
        "outputId": "dfe65d6c-42a4-4a5c-aab2-5913279787d6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SafetyDataset(Dataset):\n",
        "    def __init__(self, df):\n",
        "        self.df = df\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.df.iloc[idx]"
      ],
      "metadata": {
        "id": "RbMN3OhGhiUC"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPSTB2oiiKv1",
        "outputId": "d05b231d-ca25-4b2a-96d4-c8b2e03cbeaf"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def transformer_collate_fn(batch, tokenizer):\n",
        "\n",
        "  sentences, labels = [], []\n",
        "\n",
        "  for data in batch:\n",
        "    sentences.append(data['text'])\n",
        "    labels.append(data['binary_label'])\n",
        "\n",
        "  tokenizer_output = tokenizer(sentences, padding=True, truncation=True, max_length=512, return_tensors=\"pt\")\n",
        "  labels = F.one_hot(torch.tensor(labels).type(torch.LongTensor), num_classes=2).type(torch.FloatTensor)\n",
        "\n",
        "  return tokenizer_output, labels"
      ],
      "metadata": {
        "id": "BDqffFR8iXHh"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Finetuning"
      ],
      "metadata": {
        "id": "S2ByCZOBiz5G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 16\n",
        "LR = 5e-5\n",
        "WEIGHT_DECAY = 0\n",
        "N_EPOCHS = 1\n",
        "CLIP = 1.0"
      ],
      "metadata": {
        "id": "ZPyXt-kcixxy"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model,\n",
        "                 dataloader,\n",
        "                 device):\n",
        "\n",
        "    model.eval()\n",
        "    bce_loss = nn.BCELoss()\n",
        "\n",
        "    epoch_loss = 0\n",
        "    with torch.no_grad():\n",
        "      for i, batch in enumerate(dataloader):\n",
        "\n",
        "          input, labels = batch[0], batch[1]\n",
        "\n",
        "          input = input.to(device)\n",
        "          labels = labels.to(device)\n",
        "\n",
        "          output = model(**input, labels=labels)\n",
        "          loss = output.loss\n",
        "          epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss/len(dataloader)\n",
        "\n"
      ],
      "metadata": {
        "id": "cAj4rvZ6kAL7"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_acc(model,\n",
        "                 dataloader,\n",
        "                 device):\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    epoch_loss = 0\n",
        "    with torch.no_grad():\n",
        "\n",
        "      total_correct = 0\n",
        "      total = 0\n",
        "\n",
        "      complete_output = []\n",
        "      complete_true = []\n",
        "\n",
        "      for i, batch in enumerate(dataloader):\n",
        "\n",
        "          input, labels = batch[0], batch[1]\n",
        "\n",
        "          input = input.to(device)\n",
        "          labels = labels.to(device)\n",
        "\n",
        "          output = model(**input, labels=labels)\n",
        "\n",
        "          preds = output.logits\n",
        "          output_class = torch.argmax(preds, dim=1)\n",
        "          true_class = torch.argmax(labels, dim=1)\n",
        "\n",
        "          complete_output.extend(output_class.cpu().numpy())\n",
        "          complete_true.extend(true_class.cpu().numpy())\n",
        "\n",
        "          total_correct += torch.sum(torch.where(output_class == true_class.to(device), 1, 0))\n",
        "          total += labels.size()[0]\n",
        "\n",
        "    print(f\"Total Correct = {total_correct}\")\n",
        "    return total_correct / total"
      ],
      "metadata": {
        "id": "gtOUKxm_mSA0"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.notebook import trange, tqdm\n",
        "def train(model, dataloader, opt, device, clip: float, scheduler = None):\n",
        "\n",
        "  model.train()\n",
        "  bce_loss = nn.BCELoss()\n",
        "\n",
        "  epoch_loss = 0.0\n",
        "  progress_bar = tqdm(dataloader, desc=f\"Epoch {epoch + 1}\", leave=True)\n",
        "  for batch in progress_bar:\n",
        "      input, labels = batch[0], batch[1]\n",
        "\n",
        "      input = input.to(device)\n",
        "      labels = labels.to(device)\n",
        "\n",
        "      opt.zero_grad()\n",
        "\n",
        "      output = model(**input, labels=labels)\n",
        "      loss = output.loss\n",
        "\n",
        "\n",
        "      loss.backward()\n",
        "      torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "\n",
        "      opt.step()\n",
        "\n",
        "      if scheduler is not None:\n",
        "        scheduler.step()\n",
        "\n",
        "      epoch_loss += loss.item()\n",
        "      progress_bar.set_postfix({'loss': loss.item()})\n",
        "\n",
        "  return epoch_loss / len(dataloader)"
      ],
      "metadata": {
        "id": "s_ZIfcm0jIYY"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files = [\"/content/discrimination.csv\", \"/content/hci_harms_df.csv\", \"/content/malicious_activity.csv\", \"/content/misinfo.csv\"]"
      ],
      "metadata": {
        "id": "4MWAPX9unRqP"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "domains = [\"discrimination\", \"hci\", \"malicious_activity\", \"misinfo\"]"
      ],
      "metadata": {
        "id": "4y8PraDpoO3p"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import random_split\n",
        "from transformers import AutoModel, AutoTokenizer, AutoModelForSequenceClassification\n",
        "from functools import partial\n",
        "import time\n",
        "\n",
        "bert_model_name = \"bert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(bert_model_name)\n",
        "\n",
        "for i,file in enumerate(files):\n",
        "  print(f\"Domain: {domains[i]}\")\n",
        "  bert_model = AutoModelForSequenceClassification.from_pretrained(bert_model_name, num_labels = 2, output_hidden_states = True)\n",
        "  optimizer = optim.Adam(bert_model.parameters(), lr=LR)\n",
        "\n",
        "  bert_model = bert_model.to(device)\n",
        "\n",
        "  for params in bert_model.base_model.parameters():\n",
        "      params.requires_grad = True\n",
        "\n",
        "\n",
        "  dataset = SafetyDataset(pd.read_csv(file))\n",
        "\n",
        "  total_size = len(dataset)\n",
        "  train_size = int(0.8 * total_size)  # 80% for training\n",
        "  val_size = int(0.1 * total_size)    # 10% for validation\n",
        "  test_size = total_size - train_size - val_size\n",
        "\n",
        "\n",
        "  best_val_loss = float('inf')\n",
        "\n",
        "  train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
        "\n",
        "  train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=BATCH_SIZE, \\\n",
        "                                collate_fn=partial(transformer_collate_fn, tokenizer=tokenizer))\n",
        "  val_dataloader = DataLoader(val_dataset, shuffle=True, batch_size=BATCH_SIZE, \\\n",
        "                                collate_fn=partial(transformer_collate_fn, tokenizer=tokenizer))\n",
        "  test_dataloader = DataLoader(test_dataset, shuffle=True, batch_size=BATCH_SIZE, \\\n",
        "                                collate_fn=partial(transformer_collate_fn, tokenizer=tokenizer))\n",
        "\n",
        "  scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=10, num_training_steps=N_EPOCHS*len(train_dataloader))\n",
        "\n",
        "\n",
        "  for epoch in range(N_EPOCHS):\n",
        "\n",
        "    train_loss = train(bert_model, train_dataloader, optimizer, device, CLIP, scheduler)\n",
        "    train_acc = evaluate_acc(bert_model, train_dataloader, device)\n",
        "    print(f\"Train accuracy: {train_acc}, train_loss: {train_loss}\")\n",
        "\n",
        "    valid_loss = evaluate(bert_model, val_dataloader, device)\n",
        "    valid_acc = evaluate_acc(bert_model, val_dataloader, device)\n",
        "    print(f\"Valid accuracy: {valid_acc}, Valid_loss: {valid_loss}\")\n",
        "\n",
        "    if valid_loss<best_val_loss:\n",
        "      best_val_loss = valid_loss\n",
        "      torch.save(bert_model.state_dict(), f\"{domains[i]}_bert.pt\")\n",
        "\n",
        "  bert_model.load_state_dict(f\"{domains[i]}_bert.pt\")\n",
        "  test_loss = evaluate(bert_model, test_dataloader, device)\n",
        "  test_acc = evaluate_acc(bert_model, test_dataloader, device)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "qIZskZGqkAGs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qGpmy4XTkADv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JPW5ULyLj_6r"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}