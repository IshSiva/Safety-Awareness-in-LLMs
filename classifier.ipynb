{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jFXud85HttT9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pickle as pkl\n",
        "import pandas as pd\n",
        "import torch.utils.data as data\n",
        "from tqdm.notebook import trange, tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "  DEVICE = torch.device(\"cuda\")\n",
        "else:\n",
        "  DEVICE = torch.device(\"cpu\")\n",
        "print(\"Using device:\", DEVICE)\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UY2-En1a6im_",
        "outputId": "2909805b-2914-44cf-c8c8-328f42d61449"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset and Dataloader"
      ],
      "metadata": {
        "id": "i-WbKins13FV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ModelActivations(data.Dataset):\n",
        "  \"\"\"Activations dataset\"\"\"\n",
        "\n",
        "  def __init__(self, file_name, mode, layer_num=32):\n",
        "\n",
        "    if mode == \"fuse\":\n",
        "      pass\n",
        "    elif mode == \"individual\":\n",
        "\n",
        "      with open(file_name, \"rb\") as f:\n",
        "        inp_dict = pkl.load(f)\n",
        "\n",
        "      layer_activations = np.asarray(inp_dict[\"activations\"][layer_num])\n",
        "\n",
        "      self.activations = layer_activations\n",
        "      self.labels = np.asarray(inp_dict[\"labels\"])\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.activations)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    curr_activations = self.activations[idx]\n",
        "    curr_label = self.labels[idx]\n",
        "    curr_activations = np.expand_dims(curr_activations, axis=0)\n",
        "    curr_label = np.expand_dims(curr_label, 0)\n",
        "\n",
        "    return torch.tensor(curr_activations, dtype=torch.float32), torch.tensor(curr_label, dtype=torch.float32)\n",
        "\n"
      ],
      "metadata": {
        "id": "UGVr7xAo1253"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Binary Classifier Model"
      ],
      "metadata": {
        "id": "5FFAgMei1mMq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class SafetyClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.hidden_1 = nn.Linear(4096, 1024)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.hidden_2 = nn.Linear(1024, 256)\n",
        "        self.hidden_3 = nn.Linear(256, 32)\n",
        "        self.output = nn.Linear(32, 1)\n",
        "\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "\n",
        "    def forward(self, batch):\n",
        "      batch = [x.to(DEVICE) for x in batch]\n",
        "      x, labels = batch\n",
        "      x = self.relu(self.hidden_1(x))\n",
        "      x = self.relu(self.hidden_2(x))\n",
        "      x = self.relu(self.hidden_3(x))\n",
        "      x = self.sigmoid(self.output(x))\n",
        "      return x, labels"
      ],
      "metadata": {
        "id": "cBBqvKXVyPRK"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validate (model, data_loader, criterion):\n",
        "  bce_loss = nn.BCELoss()\n",
        "  with tqdm(data_loader, unit=\"batch\", total=len(data_loader)) as batch_iterator:\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    for i, batch_data in enumerate(batch_iterator, start=1):\n",
        "\n",
        "        output, target = model.forward(batch_data)\n",
        "        output = output.flatten()\n",
        "        target = target.flatten()\n",
        "\n",
        "        loss = bce_loss(output, target)\n",
        "        val_loss += loss.item()\n",
        "\n",
        "        batch_iterator.set_postfix(mean_loss=val_loss / i, current_loss=loss.item(), total_loss = val_loss)\n",
        "\n",
        "  return val_loss"
      ],
      "metadata": {
        "id": "zoLFcwGVIVF2"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def training(model, train_dataloader, val_dataloader, num_epochs, criterion, optimizer, file_path=None):\n",
        "  val_loss_lst = []\n",
        "  train_loss_lst = []\n",
        "  bce_loss = nn.BCELoss()\n",
        "\n",
        "  for epoch in trange(num_epochs, desc=\"training\", unit=\"epoch\"):\n",
        "\n",
        "    with tqdm(train_dataloader, desc=\"epoch {}\".format(epoch + 1), unit=\"batch\", total=len(train_dataloader)) as batch_iterator:\n",
        "        model.train()\n",
        "        total_loss = 0.0\n",
        "        running_loss = 0.0\n",
        "        for i, batch_data in enumerate(batch_iterator, start=1):\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            output, target = model(batch_data)\n",
        "            output = torch.squeeze(output,dim=2)\n",
        "\n",
        "            loss = criterion(output, target)\n",
        "            total_loss += loss.item()\n",
        "            running_loss += bce_loss(output, target).item()\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            batch_iterator.set_postfix(mean_loss=total_loss / i, current_loss=loss.item(), total_loss=total_loss)\n",
        "\n",
        "            if(i%200 == 0):\n",
        "              print(f\"Running Train Loss: {running_loss/200}\")\n",
        "              running_loss = 0.0\n",
        "\n",
        "        train_loss_lst.append(total_loss)\n",
        "\n",
        "\n",
        "    print(\"Validation Set\")\n",
        "    val_loss = validate(model, val_dataloader, criterion)\n",
        "    val_loss_lst.append(val_loss)\n",
        "\n",
        "    if file_path is not None:\n",
        "      torch.save(model.state_dict(), file_path)\n",
        "  return model"
      ],
      "metadata": {
        "id": "a5ir7BRODoNr"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Runner"
      ],
      "metadata": {
        "id": "07AQ3L803Jg9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = SafetyClassifier().to(device=DEVICE)"
      ],
      "metadata": {
        "id": "eaI9VRI110wK"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = ModelActivations(\"/content/do_not_answer_en.pkl\", mode=\"individual\", layer_num=16)"
      ],
      "metadata": {
        "id": "tcRdXSUY3UHB"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = torch.utils.data.DataLoader(\n",
        "            dataset,\n",
        "            batch_size=32,\n",
        "            shuffle=True\n",
        "        )"
      ],
      "metadata": {
        "id": "6sd7o8xY3UEI"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_dataloader = torch.utils.data.DataLoader(\n",
        "            dataset,\n",
        "            batch_size=32,\n",
        "            shuffle=True\n",
        "        )"
      ],
      "metadata": {
        "id": "CexH0iRn3UB0"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = torch.nn.BCELoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0005)\n",
        "\n",
        "model = training(model, train_dataloader, val_dataloader, 2, criterion, optimizer)"
      ],
      "metadata": {
        "id": "ejfmxLJK3T_D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qoxRoUCZ72Yt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5NrOQof-8Llr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}