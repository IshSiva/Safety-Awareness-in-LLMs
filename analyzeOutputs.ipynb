{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle as pkl\n",
    "import numpy as np\n",
    "files = os.listdir('./model_output/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_class_mapping = {\n",
    "    0: 1, 1: 0, 2: 1, 3: 0, 4: 1, 5:1, 6:1, 7:1, 8:1, 9:1, 10:1, 11:1, 12:1, 13:1, \\\n",
    "    14:1, 15:1, 16:1, 17:0, 18:1, 19:0, 20:1, 21:0, 22:1, 23:0, 24: 1 ,25:1, 26: 0, \\\n",
    "    27: 1, 28: 0, 29:1, 30: 0, 31:0, 32: 1\n",
    "}\n",
    "\n",
    "DOMAIN_INDEX_MAPPING = {\n",
    "    \"Discrimination, Exclusion, Toxicity\": 1,\n",
    "    \"Misinformation\": 2,\n",
    "    \"HCI harms\": 3,\n",
    "    \"Malicious Uses\": 4,\n",
    "    \"Information Hazards\": 5\n",
    "}\n",
    "\n",
    "DOMAIN_FILE_MAPPING = {\n",
    "    1: [\"toxigen.pkl\", \"hate_speech.pkl\", \"adult_content.pkl\"],\n",
    "    2: [\"covid_fake_news.pkl\", \"true_false.pkl\", \"mis_information.pkl\"],\n",
    "    3: [\"student_anxiety.pkl\"],\n",
    "    4: [\"bullying.pkl\"],\n",
    "    5: [\"do_not_answer_en.pkl\"]\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discrimination, Exclusion, Toxicity\n",
      "toxigen.pkl\n",
      "adult_content.pkl\n",
      "hate_speech.pkl\n",
      "{'Discrimination, Exclusion, Toxicity': {'accuracy': 0.557161629434954, 'precision': 0.3581081081081081, 'recall': 0.9763157894736842, 'f1_score': 0.5240112994350282, 'auc_roc_score': 0.697002027836667, 'failure_rate': 0.46577746577746576}}\n",
      "Misinformation\n",
      "mis_information.pkl\n",
      "covid_fake_news.pkl\n",
      "true_false.pkl\n",
      "{'Discrimination, Exclusion, Toxicity': {'accuracy': 0.557161629434954, 'precision': 0.3581081081081081, 'recall': 0.9763157894736842, 'f1_score': 0.5240112994350282, 'auc_roc_score': 0.697002027836667, 'failure_rate': 0.46577746577746576}, 'Misinformation': {'accuracy': 0.5763962065331928, 'precision': 0.5051740357478833, 'recall': 0.6588957055214724, 'f1_score': 0.5718849840255591, 'auc_roc_score': 0.58660390077551, 'failure_rate': 0.36733333333333335}}\n",
      "HCI harms\n",
      "student_anxiety.pkl\n",
      "{'Discrimination, Exclusion, Toxicity': {'accuracy': 0.557161629434954, 'precision': 0.3581081081081081, 'recall': 0.9763157894736842, 'f1_score': 0.5240112994350282, 'auc_roc_score': 0.697002027836667, 'failure_rate': 0.46577746577746576}, 'Misinformation': {'accuracy': 0.5763962065331928, 'precision': 0.5051740357478833, 'recall': 0.6588957055214724, 'f1_score': 0.5718849840255591, 'auc_roc_score': 0.58660390077551, 'failure_rate': 0.36733333333333335}, 'HCI harms': {'accuracy': 0.3520286396181384, 'precision': 0.1138353765323993, 'recall': 0.6372549019607843, 'f1_score': 0.19316493313521543, 'auc_roc_score': 0.47487745098039214, 'failure_rate': 0.162}}\n",
      "Malicious Uses\n",
      "bullying.pkl\n",
      "{'Discrimination, Exclusion, Toxicity': {'accuracy': 0.557161629434954, 'precision': 0.3581081081081081, 'recall': 0.9763157894736842, 'f1_score': 0.5240112994350282, 'auc_roc_score': 0.697002027836667, 'failure_rate': 0.46577746577746576}, 'Misinformation': {'accuracy': 0.5763962065331928, 'precision': 0.5051740357478833, 'recall': 0.6588957055214724, 'f1_score': 0.5718849840255591, 'auc_roc_score': 0.58660390077551, 'failure_rate': 0.36733333333333335}, 'HCI harms': {'accuracy': 0.3520286396181384, 'precision': 0.1138353765323993, 'recall': 0.6372549019607843, 'f1_score': 0.19316493313521543, 'auc_roc_score': 0.47487745098039214, 'failure_rate': 0.162}, 'Malicious Uses': {'accuracy': 0.34886649874055414, 'precision': 0.09683098591549295, 'recall': 0.9322033898305084, 'f1_score': 0.17543859649122803, 'auc_roc_score': 0.6171221030785194, 'failure_rate': 0.206}}\n",
      "Information Hazards\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import (\n",
    "    precision_recall_curve,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score\n",
    ")\n",
    "\n",
    "def processOutput(input):\n",
    "    preds = []\n",
    "    for x in input:\n",
    "        if 'YES' in x and 'NO' in x:\n",
    "            preds.append(2)\n",
    "        elif 'YES' in x:\n",
    "            preds.append(0)\n",
    "        elif 'NO' in x:\n",
    "            preds.append(1)\n",
    "        else:\n",
    "            preds.append(2)\n",
    "\n",
    "    return preds\n",
    "\n",
    "result = {}\n",
    "for test_domain in DOMAIN_INDEX_MAPPING.keys():\n",
    "    print(test_domain)\n",
    "    if(test_domain == \"Information Hazards\"):\n",
    "        continue\n",
    "    predictions = []\n",
    "    labels = []\n",
    "    for file in files:\n",
    "        if file in DOMAIN_FILE_MAPPING[DOMAIN_INDEX_MAPPING[test_domain]]:\n",
    "            print(file)\n",
    "            data = pkl.load(open(f\"./model_output/{file}\", \"rb\"))\n",
    "            predictions.extend(data['output'])\n",
    "            labels.extend(data['labels'])\n",
    "\n",
    "    preds = np.array(processOutput(predictions))\n",
    "    labels = np.array([index_class_mapping[x] for x in labels])\n",
    "\n",
    "    failure = preds!=2\n",
    "    failure_rate = np.sum(1 - 1 * failure)/len(preds)\n",
    "    preds = preds[failure]\n",
    "    labels = labels[failure]\n",
    "\n",
    "    result[test_domain] = { 'accuracy': accuracy_score(labels, preds),\n",
    "            'precision': precision_score(labels, preds),\n",
    "            'recall': recall_score(labels, preds),\n",
    "            'f1_score': f1_score(labels, preds),\n",
    "            'auc_roc_score': roc_auc_score(labels, preds),\n",
    "            'failure_rate': failure_rate\n",
    "            }\n",
    "    print(result)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl.dump(result, open(\"baseline.pkl\", \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
